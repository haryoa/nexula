Goal : Ez benchmark on all method
---------------------------------
Problem:
- Lazy on collecting all different pieces of code
- Sometimes, lazy to pre-process in every code
Component:
- NLP
    - Classification
        - Data Reader (skr 1 dulu)
            - json
            - csv
            - plain (x file and file separated)
        - Preprocesser (Next Version)
        - Feature Representation (TF-IDF, Word2vec, Glove, Fastext, ELMO, BERT)
        - Boomer Algorithm
            - All Scikit-learn algorithm
            - XGBoost
        - Training Configuration
            - Split : train-valid-test random
            - Cross Validation K-fold (useful)
            - Default input
        - Millenial Algorithm
            - LSTM, BI-LSTM, CNN, GRU, GRU, BI-GRU, CNN, etc
        - GenZ Algorithm
            - BERT
            - ALBERT
            - ROBERTA
            - ELMO
        - Advance Feature (Next Version)
            - Warm up
            - Label Smoothing
            - Etc
        - Output
            - Write into json file about all of experiment
    - Sequential
        - Hyperparameter Tuning (Next Version)
    
Feature:
- Extendable, can write your own function
- Config in yaml
- Logging gracefully (can write log into file and log into terminal)